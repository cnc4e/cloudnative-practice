issues:
  - title: ワーカーの拡張
    body: |
      **本issueは内容を確認するだけでクローズしてください。**

      K8sのPodはEC2などのワーカーノード上で動作します。Podが増えるとワーカーノードのリソースが不足することがあります。 その場合、ワーカーノードを追加してリソースを確保する必要があります。

      # ワーカーの拡張の必要性
      - Podの数が増えると、既存のワーカーノードのリソース（CPU、メモリ）が不足することがある
      - リソース不足により、Podがスケジュールされず、アプリケーションの可用性が低下する
      - 手動でノードを追加するのは手間がかかり、運用負荷が増大する
      - 自動でノードを追加・削除する仕組みが必要

      # 解決策
      - クラスターオートスケーラーを使用してノードの自動拡張を実現する
      - Fargateなどのオンデマンド型のワーカーノードを利用する
      - Karpenterを使用してノードの自動拡張を実現する

      本プラクティスでは、EKS AutoModeを使用しています。EKS AutoMode は Karpenter 使い、ノードの自動拡張を実現します。

      # Karpenterによるワーカーの自動拡張
      - KarpenterはEKSクラスターのリソース使用状況を監視し、必要に応じてノードを自動で追加・削除する
      - Podのリソース要求に基づいて最適なノードタイプを選択し、コスト効率の良いリソースを提供する
  - title: メトリクスサーバーの導入
    body: |
      Podの自動拡張を行うHPAやVPAを行うにはPodの現在のリソース使用量を取得する必要があります。Kubernetesではメトリクスサーバーを導入することで、リソース使用量を収集し、HPAやVPAに提供します。

      # メトリクスサーバーの必要性
      - KubernetesのHorizontal Pod Autoscaler（HPA）やVertical Pod Autoscaler（VPA）にはメトリクス情報が必要
      - `kubectl top nodes`や`kubectl top pods`コマンドでリソース使用量を確認するためにメトリクスが必要
      - メトリクスサーバーがないと、CPUやメモリベースのスケーリングができない
      - Kubernetesの標準的な監視機能を利用するための基盤となる
      
      # 解決策
      - YAMLマニフェストを直接適用する方法
      - Helmチャートを使用する方法
      - EKSアドオンとして導入する方法
      
      本プラクティスでは、EKSアドオンを使用してメトリクスサーバーを導入します。EKSアドオンを使うことで、AWS管理下でのアップデートや互換性保証が得られます。

      # EKSアドオンによるメトリクスサーバー
      - メトリクスサーバーはEKSのコミュニティアドオンとして提供されている
        - コミュニティアドオンはAWSが公式にサポートしているわけではない
        - EKSクラスターのバージョンとの互換性が保証されている
        - マニフェストの管理やアップデートが容易
      
      # プラクティス
      
      - EKSアドオンとしてメトリクスサーバーを導入する
        - Terraformを使用してEKSアドオンリソースを作成する
        - アドオンの状態を確認し、正常に動作していることを確認する
      - メトリクスサーバーの動作を確認する
        - `kubectl top nodes`コマンドでノードのリソース使用量を確認する
        - `kubectl top pods`コマンドでPodのリソース使用量を確認する
  - title: HPAによるオートスケール
    body: |
      HPAを使用してPodのオートスケールを実装することで、トラフィックの変動に自動的に対応し、リソース効率とコスト最適化を実現できます。

      # オートスケールの必要性
      - トラフィックの変動によりアプリケーションの負荷が変動する
      - 負荷が高いときはPod数を増やして性能を確保する必要がある
      - 負荷が低いときはPod数を減らしてリソースを節約したい
      - 手動でのスケールは運用負荷が高く、対応が遅れる可能性がある
      
      # 解決策
      - Horizontal Pod Autoscaler (HPA) でCPU使用率ベースの自動スケーリング
      - Vertical Pod Autoscaler (VPA) でリソース使用量の自動調整
      - Custom Metrics を使用したより詳細な指標によるスケーリング
      
      本プラクティスでは HPA を使用してCPU使用率ベースの水平スケールを実装します。

      # HPAの仕組み
      - HPAはDeploymentのレプリカ数を動的に調整する
      - CPU使用率、メモリ使用率、カスタムメトリクスを監視指標として使用可能
      - 指定した閾値を超えるとスケールアウト、下回るとスケールインを実行
      - Metrics Server が提供するメトリクスを基に判断を行う
      
      ## HPA実装手順
      
      - Metrics Serverを確認・インストールする
      - アプリケーションのDeploymentにresources.requestsを設定する
      - HPAリソースを作成し、スケーリング設定を定義する
      - 負荷テストでスケールアウト・スケールインを確認する

      # プラクティス
      
      ## 前提

      - メトリクスサーバーの導入が完了していること

      ## 内容

      - frontendに対してHPAを設定する
        - `resources.requests`を設定してCPUリクエストを指定する
        - HPAリソースを作成する
          - CPU使用率70%でスケールアウト開始
          - 最大レプリカ数: 3
      - 動作確認
        - `httpd`のイメージを使ったPodを用意する
        - `httpd`Podから以下コマンドで継続的にリクエストを送る
          - `ab -n 100000 -c 10 http://frontend/`
        - frontendのPod数が増えることを確認する
  - title: In-Place Pod Vertical Scaling (IPVS)によるリソース増強
    body: |
      Kubernetes 1.33からベータ機能として利用可能になったIn-Place Pod Vertical Scaling (IPVS)を使用するとPodを再起動せずにリソース制限を動的に調整することができます。従来のスケールアップと異なり、Podのダウンタイムなしでリソースを増減できます。

      # IPVSの必要性
      - アプリケーションの負荷が変動し、CPUやメモリの要求量が変わる
      - 従来のスケールアップはPodを再起動するため、短時間のダウンタイムが発生する
      - ステートフルなアプリケーションやlong-runningなジョブでは再起動による影響が大きい
      - リアルタイムでリソース調整を行い、可用性を維持したい

      # IPVSの仕組み
      - `InPlacePodVerticalScaling`フィーチャーゲートを有効にする必要がある。(EKS 1.33以降でデフォルト有効)
      - Podのspecで`resizePolicy`を設定することで、in-place resizeが可能になる
        - リサイズ時にコンテナを再起動するかどうかを指定できる
      - kubeletがコンテナランタイムと連携してリソース制限を動的に変更する
      - PodのStatusで現在のリソース状態とリサイズの進行状況を確認できる

      # プラクティス

      ## 前提条件
      - EKSクラスターが`v1.33`以上であること

      ## 基本的なIPVS実装

      - FrontendまたはBackendのDeploymentに対してIPVSを設定する
        - `resizePolicy`でメモリとCPUのリサイズポリシーを指定する
          - CPUはコンテナの再起動なしでリサイズ可能
          - メモリはコンテナを再起動してリサイズ
      - 動作確認
        - cpu
          - 以下の様なコマンドでリサイズする
            ```
            kubectl -n default patch pod Pod名 --subresource resize --patch '{"spec":{"containers":[{"name":"コンテナ名", "resources":{"requests":{"cpu":"リクエスト"}, "limits":{"cpu":"リミット"}}}]}}'
            ```
          - Podが再起動**しない**
          - コンテナ内で以下コマンドを実行するとリソース量が分かる
            ```
            cat /sys/fs/cgroup/cpu.max
            ```
        - memory
          - 以下の様なコマンドでリサイズする
            ```
            kubectl -n default patch pod Pod名 --subresource resize --patch '{"spec":{"containers":[{"name":"コンテナ名", "resources":{"requests":{"memory":"リクエスト"}, "limits":{"memory":"リミット"}}}]}}'
            ```
          - Podが再起動**する**
          - コンテナ内で以下コマンドを実行するとリソース量が分かる
            ```
            cat /sys/fs/cgroup/memory.max
            ```
