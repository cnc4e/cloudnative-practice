issues:
  - title: ワーカーの拡張
    body: |
      **本issueは内容を確認するだけでクローズしてください。**

      K8sのPodはEC2などのワーカーノード上で動作します。Podが増えるとワーカーノードのリソースが不足することがあります。 その場合、ワーカーノードを追加してリソースを確保する必要があります。

      # ワーカーの拡張の必要性
      - Podの数が増えると、既存のワーカーノードのリソース（CPU、メモリ）が不足することがある
      - リソース不足により、Podがスケジュールされず、アプリケーションの可用性が低下する
      - 手動でノードを追加するのは手間がかかり、運用負荷が増大する
      - 自動でノードを追加・削除する仕組みが必要

      # 解決策
      - クラスターオートスケーラーを使用してノードの自動拡張を実現する
      - Fargateなどのオンデマンド型のワーカーノードを利用する
      - Karpenterを使用してノードの自動拡張を実現する

      本プラクティスでは、EKS AutoModeを使用しています。EKS AutoMode は Karpenter 使い、ノードの自動拡張を実現します。

      # Karpenterによるワーカーの自動拡張
      - KarpenterはEKSクラスターのリソース使用状況を監視し、必要に応じてノードを自動で追加・削除する
      - Podのリソース要求に基づいて最適なノードタイプを選択し、コスト効率の良いリソースを提供する
  - title: メトリクスサーバーの導入
    body: |
      Podの自動拡張を行うHPAやVPAを行うにはPodの現在のリソース使用量を取得する必要があります。Kubernetesではメトリクスサーバーを導入することで、リソース使用量を収集し、HPAやVPAに提供します。

      # メトリクスサーバーの必要性
      - KubernetesのHorizontal Pod Autoscaler（HPA）やVertical Pod Autoscaler（VPA）にはメトリクス情報が必要
      - `kubectl top nodes`や`kubectl top pods`コマンドでリソース使用量を確認するためにメトリクスが必要
      - メトリクスサーバーがないと、CPUやメモリベースのスケーリングができない
      - Kubernetesの標準的な監視機能を利用するための基盤となる
      
      # 解決策
      - YAMLマニフェストを直接適用する方法
      - Helmチャートを使用する方法
      - EKSアドオンとして導入する方法
      
      本プラクティスでは、EKSアドオンを使用してメトリクスサーバーを導入します。EKSアドオンを使うことで、AWS管理下でのアップデートや互換性保証が得られます。

      # EKSアドオンによるメトリクスサーバー
      - メトリクスサーバーはEKSのコミュニティアドオンとして提供されている
        - コミュニティアドオンはAWSが公式にサポートしているわけではない
        - EKSクラスターのバージョンとの互換性が保証されている
        - マニフェストの管理やアップデートが容易
      
      # プラクティス
      
      - EKSアドオンとしてメトリクスサーバーを導入する
        - Terraformを使用してEKSアドオンリソースを作成する
        - アドオンの状態を確認し、正常に動作していることを確認する
      - メトリクスサーバーの動作を確認する
        - `kubectl top nodes`コマンドでノードのリソース使用量を確認する
        - `kubectl top pods`コマンドでPodのリソース使用量を確認する
  - title: HPAによるオートスケール
    body: |
      HPAを使用してPodのオートスケールを実装することで、トラフィックの変動に自動的に対応し、リソース効率とコスト最適化を実現できます。

      # オートスケールの必要性
      - トラフィックの変動によりアプリケーションの負荷が変動する
      - 負荷が高いときはPod数を増やして性能を確保する必要がある
      - 負荷が低いときはPod数を減らしてリソースを節約したい
      - 手動でのスケールは運用負荷が高く、対応が遅れる可能性がある
      
      # 解決策
      - Horizontal Pod Autoscaler (HPA) でCPU使用率ベースの自動スケーリング
      - Vertical Pod Autoscaler (VPA) でリソース使用量の自動調整
      - Custom Metrics を使用したより詳細な指標によるスケーリング
      
      本プラクティスでは HPA を使用してCPU使用率ベースの水平スケールを実装します。

      # HPAの仕組み
      - HPAはDeploymentのレプリカ数を動的に調整する
      - CPU使用率、メモリ使用率、カスタムメトリクスを監視指標として使用可能
      - 指定した閾値を超えるとスケールアウト、下回るとスケールインを実行
      - Metrics Server が提供するメトリクスを基に判断を行う
      
      ## HPA実装手順
      
      - Metrics Serverを確認・インストールする
      - アプリケーションのDeploymentにresources.requestsを設定する
      - HPAリソースを作成し、スケーリング設定を定義する
      - 負荷テストでスケールアウト・スケールインを確認する

      # プラクティス
      
      ## 前提

      - メトリクスサーバーの導入が完了していること

      ## 内容

      - frontendに対してHPAを設定する
        - `resources.requests`を設定してCPUリクエストを指定する
        - HPAリソースを作成する
          - CPU使用率70%でスケールアウト開始
          - 最大レプリカ数: 3
      - 動作確認
        - `httpd`のイメージを使ったPodを用意する
        - `httpd`Podから以下コマンドで継続的にリクエストを送る
          - `ab -n 100000 -c 10 http://frontend/`
        - frontendのPod数が増えることを確認する
